{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "sys.path.insert(-1, os.getcwd())\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "os.environ['THEANO_FLAGS'] = \"device=cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "from ctc import ctc_loss as my_ctc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "max_labsize = 20\n",
    "voca_size = 20  # excluding blank\n",
    "max_seqsize = 100\n",
    "blank = -1\n",
    "\n",
    "labsize = np.random.randint(\n",
    "    1, max_labsize + 1, size=(batch_size,), dtype=np.int32)\n",
    "labsize[0] = max_labsize\n",
    "labsize[1] = 1\n",
    "labsize[2] = max_labsize\n",
    "labsize[3] = max_labsize\n",
    "\n",
    "labels = np.random.randint(\n",
    "    0, voca_size,\n",
    "    size=(batch_size, max_labsize), dtype=np.int32)\n",
    "for b in range(batch_size):\n",
    "    labels[b, labsize[b]:] = blank\n",
    "\n",
    "seqsize = np.array([\n",
    "    np.random.randint(labsize[i] + 1, max_seqsize + 1)\n",
    "    for i in range(batch_size)], dtype=np.int32)\n",
    "\n",
    "linout = np.random.randn(\n",
    "    max_seqsize, batch_size, voca_size + 1).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th_linout_var = T.tensor3()\n",
    "th_seqsize_var = T.ivector()\n",
    "th_labels_var = T.imatrix()\n",
    "th_labsize_var = T.ivector()\n",
    "th_loss = my_ctc_loss(th_linout_var, th_seqsize_var, th_labels_var, th_labsize_var)\n",
    "\n",
    "def dense_to_sparse(x):\n",
    "    idx = tf.where(tf.greater_equal(x, 0))\n",
    "    return tf.SparseTensor(idx, tf.gather_nd(x, idx), tf.shape(x, out_type=tf.int64))\n",
    "\n",
    "tf_linout_var = tf.placeholder(tf.float32, shape=[max_seqsize, batch_size, voca_size + 1])\n",
    "tf_seqsize_var = tf.placeholder(tf.int32, shape=[batch_size])\n",
    "tf_labels_var = tf.placeholder(tf.int32, shape=[batch_size, max_labsize])\n",
    "\n",
    "tf_loss = tf.nn.ctc_loss(\n",
    "    dense_to_sparse(tf_labels_var), tf_linout_var,\n",
    "    sequence_length=tf_seqsize_var,\n",
    "    time_major=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    tf_result = sess.run(\n",
    "        tf_loss, {\n",
    "            tf_linout_var: linout,\n",
    "            tf_seqsize_var: seqsize,\n",
    "            tf_labels_var: labels\n",
    "        })\n",
    "    \n",
    "    th_results = th_loss.eval({\n",
    "        th_linout_var: linout,\n",
    "        th_seqsize_var: seqsize,\n",
    "        th_labels_var: labels,\n",
    "        th_labsize_var: labsize\n",
    "    })\n",
    "    \n",
    "    print(np.abs(tf_result - th_results) / tf_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_g = tf.gradients(xs=tf_linout_var, ys=tf.reduce_sum(tf_loss))[0]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf_grad = sess.run(\n",
    "        tf_g, {\n",
    "            tf_linout_var: linout,\n",
    "            tf_seqsize_var: seqsize,\n",
    "            tf_labels_var: labels\n",
    "        })\n",
    "    \n",
    "    th_grad = theano.grad(th_loss.sum(), wrt=th_linout_var).eval({\n",
    "        th_linout_var: linout,\n",
    "        th_seqsize_var: seqsize,\n",
    "        th_labels_var: labels,\n",
    "        th_labsize_var: labsize\n",
    "    })\n",
    "    \n",
    "    print(np.abs(tf_grad - th_grad) / (tf_grad + .000001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th_grad[:, 1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_grad[:, 1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
